---
title: <h1> __R Code Logistische Regression__ </h1>
author: "Xuan Son Le (4669361), Freie Universität Berlin"
date: "04/04/2018"
output: 
  pdf_document: 
    keep_tex: yes
    latex_engine: pdflatex
    number_sections: yes
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


1. Datensatz einlesen

```{r Datendatz einlesen}
df <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
#df$gre <- df$gre/100

```

2. Implementieren Maximum Likelihood Schätzung

```{r Maximum Likelihood Schätzung}
maxLikelihood <- function(formula, data) {
    
    outcome <- rownames(attr(terms(formula),"factors"))[1]
    
    y <- as.numeric(as.matrix(data[,match(outcome,colnames(data))]))
    X <- as.matrix(model.matrix(formula, data))
    
    loglike <- function(beta) {
        
        eta <- X%*%beta

        exp_eta <- exp(eta)

        pi_wkt <- exp_eta / (1 + exp_eta)
        
        result <- sum (crossprod(y,eta) - sum(log(1+exp(eta))))
        
        return (-result) 
    }
    
    logit.gr <- function(beta) {

        grad <- beta*0
    
        eta <- X%*%beta #
    
        exp_eta <- exp(eta) # 
        
        pi_wkt <- exp_eta / (1 + exp_eta) # 
        
        for (k in 1:as.numeric(ncol(X))) { 
          grad[k] <- sum(X[,k] * (y - pi_wkt))
          }
        
        return (-grad) 
    }
    
    initial_beta <- rep(0, times = ncol(X))
    
    mle = optim(initial_beta, fn = loglike, gr = logit.gr, method="BFGS", 
                control=list(trace = TRUE, maxit = 1000), hessian=TRUE)
    
    #out = list(beta=mle$par,vcov=solve(mle$hessian),ll=2*mle$value)
    
    mle$par
}

df$rank = factor(df$rank)

modell <- as.formula("admit ~ gre + gpa + rank")

maxLikelihood(modell,df)
```

3. Vergleich mit dem Standard Logit-Modell von R

```{r Standard Logit-Modell von R}
glm <- glm(admit ~ gre + gpa + rank, family = binomial, data = df)
coef(glm)
```

